<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-02-23T05:04:20+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Dossiers</title><subtitle>Stories with a data twist</subtitle><author><name>Giree</name></author><entry><title type="html">Semantically Distinct Key Phrase Extraction</title><link href="http://localhost:4000/semantically-distinct-key-phrase-extraction/" rel="alternate" type="text/html" title="Semantically Distinct Key Phrase Extraction" /><published>2022-02-19T00:00:00+00:00</published><updated>2022-02-19T00:00:00+00:00</updated><id>http://localhost:4000/semantically-distinct-key-phrase-extraction</id><content type="html" xml:base="http://localhost:4000/semantically-distinct-key-phrase-extraction/"><![CDATA[<p>Working with Hilbert Space is fascinating. It is a hash function with prefix matching properties and two hashes can be compared just like a ZIP Code or a PIN Code.  This implies that a vector in positive space can be hashed. Combining this with a typical vector transformation in NLP (say word2vec) can generate one dimensional embeddings.</p>

<p>To give an example,  consider the words in months (april, july, january) and mathematics (mathematics, deep learning, machine learning).  If we transform those words using a word vector embedding and do a hilbert hash,  it would look like the following figure</p>

<p><img src="/assets/images/hilbert_hash_example_months_maths.png" alt="Hilbert Hash for various words from word2vec )" /></p>

<p>What it implies are</p>
<ul>
  <li>If the topics are different, the hash prefix would differ</li>
  <li>We can reduce all the words in an article to set of hashes and find most common prefixes they belong</li>
  <li>The look up table can be saved as a dictionary for easy re-use. The original word vectors are no longer needed</li>
  <li>A trie can do fast look up under each subtree and can summarize/rank keywords</li>
</ul>

<p>Using this approach, the first thing we could do is to generate distinct key phrases from a given article text. The problem is caleed <strong>Key phrase extraction</strong>.  The uniqueness of this approach is that generated key phrases will be semantically distnict.</p>

<p><img src="/assets/images/steps_hilbert_hashing.png" alt="Hashing Process )" /></p>

<h2 id="output-from-the-package">Output from the package</h2>

<p><img src="/assets/images/distinct_keywords_sample_output.png" alt="Distinct Keywords Sample Output )" /></p>
<h2 id="generalization-and-benchmarks">Generalization and benchmarks</h2>
<p>The approach can be generalized to any vector embedding technique and can do semantic sentence comparison or document comparison in an unsupervised setting.  The current implementation used Trie and SortedDict for making it one of the fastest implementation.  The approach does not require any training and shown a 31% recall score while doing benchmark with KPTimes Test Data Set (20000 articles) with manual keywords 
Same preprocessing and comparison was done with KeyBert with top_n as 16 and compared.</p>

<p><img src="/assets/images/benchmark_keybert_distinct_keywords_kptimes.png" alt="KP Times Test Data Recall Score )" /></p>

<h4 id="github-link">Github Link</h4>
<p><a href="https://github.com/sahyagiri/DistinctKeywords">DistinctKeywords</a></p>]]></content><author><name>Giree</name></author><summary type="html"><![CDATA[Working with Hilbert Space is fascinating. It is a hash function with prefix matching properties and two hashes can be compared just like a ZIP Code or a PIN Code. This implies that a vector in positive space can be hashed. Combining this with a typical vector transformation in NLP (say word2vec) can generate one dimensional embeddings.]]></summary></entry><entry><title type="html">What’s near me? Space Filling Curves and Radix Tree in geospatial applications</title><link href="http://localhost:4000/whats-near-me-space-filling-curves-and-radix-tree-in-geospatial-applications/" rel="alternate" type="text/html" title="What’s near me? Space Filling Curves and Radix Tree in geospatial applications" /><published>2022-01-30T00:00:00+00:00</published><updated>2022-01-30T00:00:00+00:00</updated><id>http://localhost:4000/whats-near-me-space-filling-curves-and-radix-tree-in-geospatial-applications</id><content type="html" xml:base="http://localhost:4000/whats-near-me-space-filling-curves-and-radix-tree-in-geospatial-applications/"><![CDATA[<p>In geospatial applications, indexing and searching for things around a given point is the most common operation. Since there is latitude and longitude information, a regular look up table kind of approach is difficult and slow. The alternate approach is to use space filling curves.</p>

<p><img src="/assets/images/space_filling_curve.png" alt="Space Filling Curve (Source: Wikipedia)" /></p>

<p>We can divide the area by smaller squares and draw a non-overlapping curve passing through the squares. Each turn in the curve can be represented by a continuous value (one dimensional coordinate).  Smaller the square, the more accurate the point location in the curve will be.  For more details on Space Filling Curves, please watch the video below.</p>

<!-- Courtesy of embedresponsively.com //-->

<div class="responsive-video-container">
    <iframe src="https://www.youtube-nocookie.com/embed/x-DgL49CFlM" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
  </div>

<h2 id="s2-geometry">S2 Geometry</h2>
<p><img src="/assets/images/s2geometry.png" alt="S2Geometry (Source: s2geometry)" /></p>

<p>S2Geometry uses a radix tree implementation along with geometrical operations (near, point in line, point in polygon, overlap etc).</p>
<h2 id="openstreetmap-data-and-spatial-indexing">Openstreetmap data and spatial indexing</h2>
<p>Openstreetmap is the wikipedia of maps and geospatial information where everything is community contributed. As a developer if I have to get geospatial data (how many malls near a given location, which is the nearest highway etc), the first place to go to is openstreetmap. Being free (as in free beer), it is doing an amazing job on serving such queries.  But the best way to leverage the data is to take a dump and transform to a R-Tree.</p>

<p>I tried to look at the python ecosystem with openstreetmap and database creation and indexing (without postgres or other spatial support DB) is almost non-existant. Geopandas supports only smaller datasets and performance is too low.</p>

<h3 id="the-osm_roads-package">The OSM_Roads Package</h3>
<p>I wrote a small script which can take openstreetmap dumps, convert to a R-Tree using geohash (one of the implementations of space filling curve for latitude, longitude). The package currently can do map matching of point to a road.</p>

<p><img src="/assets/images/sample_output_osm_roads.png" alt="S2Geometry (Source: s2geometry)" /></p>

<h4 id="github-link">Github Link</h4>
<p><a href="https://github.com/sahyagiri/osm_roads">OSM Roads</a></p>]]></content><author><name>Giree</name></author><summary type="html"><![CDATA[In geospatial applications, indexing and searching for things around a given point is the most common operation. Since there is latitude and longitude information, a regular look up table kind of approach is difficult and slow. The alternate approach is to use space filling curves.]]></summary></entry><entry><title type="html">Collaborative Movie Recommendation with Word2vec</title><link href="http://localhost:4000/collaborative-movie-recommendation-with-word2vec/" rel="alternate" type="text/html" title="Collaborative Movie Recommendation with Word2vec" /><published>2021-05-08T00:00:00+00:00</published><updated>2021-05-08T00:00:00+00:00</updated><id>http://localhost:4000/collaborative-movie-recommendation-with-word2vec</id><content type="html" xml:base="http://localhost:4000/collaborative-movie-recommendation-with-word2vec/"><![CDATA[<p>We use recommendations every day from friends. Let it be a movie/ a product you want to try. We take it or discard it based on two things. First is our own experience in the domain (say we liked most of the movies by Tom Hanks. The second is how close we know/think the friend chooses (he/she likes Tom Hanks most of the time).  This is what a recommender system tries to do.</p>

<p>Be it</p>
<ul>
  <li>Google giving search results</li>
  <li>Amazon showing people who bought this item also bought</li>
  <li>Goodreads telling similar books based on your shelves. 
There are multiple ways in which these systems are designed with many parameters, ranging from age, sex, region, history of interactions, what is liked, what is disliked etc.</li>
</ul>

<p>One of the most straightforward approaches is measuring the distance between two items (how close they are) based on the users who selected (and liked) those items.  Creating a way to calculate the distance between two entities is what word2vec does. It can make representations of each product in terms of users who used/bought/liked.  There is no complex matrix factorisation or sparse matrix operations involved, very easy to update the system with new users/updates to the products.</p>

<p>To illustrate this, we can take the <strong>MovieLens 25M</strong> database with 62,000 movies rated by 162,000 users.</p>

<p>We can define two movies as similar if the majority of a set of users likes both of them.</p>

<ul>
  <li>User1: movie1, movie2, movie3, movie4</li>
  <li>User2: movie1, movie3, movie5, movie10</li>
  <li>User3: movie10, movie15,movie24, movie41</li>
</ul>

<p>Here, movie1, movie3 are possibly similar as it appears with user1 and user2 (and much more users in the list) 
After selecting movies (with bare minimum average rating) and users with approximately 30 to 400 films rated, we can train a word2vec to capture the similarity of movies based on users who liked it.</p>

<p>After that we can select those users who were not in the training set, take 10 of their most liked movies and predict what would they like.  The number of movies correctly predicted from the rest of their movies would tell us how good the recommender is</p>

<p><img src="/assets/images/movie_recommender_distribution_plot.png" alt="Movie Recommendation Distribution" /></p>

<p>Search your favourite movie and check the recommendations.</p>

<iframe src="https://pythonapps.dossiers.page:9443/" title="Movie Recommender" width="100%" height="600" frameborder="0" allowtransparency="true"></iframe>]]></content><author><name>Giree</name></author><summary type="html"><![CDATA[We use recommendations every day from friends. Let it be a movie/ a product you want to try. We take it or discard it based on two things. First is our own experience in the domain (say we liked most of the movies by Tom Hanks. The second is how close we know/think the friend chooses (he/she likes Tom Hanks most of the time). This is what a recommender system tries to do.]]></summary></entry><entry><title type="html">Semantic Similarity between documents using NLP, an illustration with job description and resume match</title><link href="http://localhost:4000/semantic-similarity-between-documents-using-nlp-an-illustration-with-job-description-and-resume-match/" rel="alternate" type="text/html" title="Semantic Similarity between documents using NLP, an illustration with job description and resume match" /><published>2021-03-10T00:00:00+00:00</published><updated>2021-03-10T00:00:00+00:00</updated><id>http://localhost:4000/semantic-similarity-between-documents-using-nlp-an-illustration-with-job-description-and-resume-match</id><content type="html" xml:base="http://localhost:4000/semantic-similarity-between-documents-using-nlp-an-illustration-with-job-description-and-resume-match/"><![CDATA[<p>Suppose that there are many Job Descriptions and you want to know the closest match of your profile against them. The normal way is to search for keywords and manually go through the words.  An alternate approach uses Natural Language Processing models that can tell the distance between words (or documents).</p>

<p>One of the best approaches to find semantic similarity between words started with the work  “<a href="https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf">A Neural Probabilistic Language Model</a>” by Yoshua Bengio ( 2003). The idea was straightforward. Make a neural network that takes a bag of k words and predicts the next word. After going through large corpora, the weights of the model will represent the words based on their semantic similarity.  Thus the “representation” of knowledge by the neural network is the best representation of the word.  The parameters in such a representation would be the number of simultaneous words in the bag and the vector’s size (8 vectors/ 16 vectors/ 32 vectors etc.).</p>

<p>This in layman’s sense, is like using a PINCODE/Latitude-Longitude. Closer values would be closer to each other.  This also means that words like bank (<strong>homonyms</strong>) will have almost equal probability to see river and cash as next words.</p>

<p><strong>“Efficient Estimation of Word Representations in Vector Space”</strong> was the next breakthrough in this aspect, and word2vec as a library became the most popular NLP library.</p>

<p>This demonstration uses word2vec trained on job description datasets to show how efficiently it can capture the semantic similarity between keywords used and show the distance between them (lower the distance, better match).</p>

<h3 id="please-wait-for-the-below-application-to-load">Please wait for the below application to load</h3>
<iframe src="https://pythonapps.dossiers.page:8443/" title="Resume-JD Matching" width="100%" height="1000" frameborder="0" allowtransparency="true"></iframe>]]></content><author><name>Giree</name></author><summary type="html"><![CDATA[Suppose that there are many Job Descriptions and you want to know the closest match of your profile against them. The normal way is to search for keywords and manually go through the words. An alternate approach uses Natural Language Processing models that can tell the distance between words (or documents).]]></summary></entry><entry><title type="html">Prospects and Nudges, how human behavior influences economics</title><link href="http://localhost:4000/prospects-and-nudges-how-human-behavior-influences-economics/" rel="alternate" type="text/html" title="Prospects and Nudges, how human behavior influences economics" /><published>2020-11-28T00:00:00+00:00</published><updated>2020-11-28T00:00:00+00:00</updated><id>http://localhost:4000/prospects-and-nudges-how-human-behavior-influences-economics</id><content type="html" xml:base="http://localhost:4000/prospects-and-nudges-how-human-behavior-influences-economics/"><![CDATA[<p>Do you often</p>

<ol>
  <li>Think your loss of 1000 bucks is compensated well by a gain of 2000</li>
  <li>Feel that there were already 3 negative incidents in a day and you made the 4th mistake just because you were pissed off with the earlier 3 incidents?</li>
  <li>Put money in buckets (emergency, outing, shopping, school)</li>
  <li>Procastenate the investment plans and retirement plans</li>
  <li>If you reviewed your slides/proposals after 6 months, feel that “did I write that crap”</li>
  <li>Often take easier bets in office than taking risky routes because the reward is not worth the risk?</li>
</ol>

<p>I do think and act in these manners and interestingly found out that I am not a rational economist (ECON) and I am one of the most 99.999999 percent persons.  There are two parts to this kind of decision making. The time it takes to think and act (quick where rational thinking takes a backseat)  is the first one. The second one is the past (immediate/distant) incidents influencing the decisions irrationally.</p>

<p>I thought this was an obvious fact and political and economic think tanks would have already made theories about this. It came as a shocking surprise to me that this field of behavioral economics is very new and all the market theories and policies formed never considered human errors and procrastinating behaviors. More interestingly, the stock market investments, the retirement plans to everything we believed in had lousy foundations till the late ’90s.  This is also the reason to over-invest in certain types of markets and the crashes that followed (like the housing bubble in the USA).</p>

<p>So, how do we take care of ourselves if 99.9999999999s of us are this way and often the others too in most of the emotional situations? How do we improve the voluntary sign-up for organ donations, making people to save more for the future, making a better judgment about stock market collapses by overinvesting?</p>

<p>This is exactly what is narrated in the book <em>Misbehaving, Making of behavioral economics</em> is talking about. It is one hell of a journey by Prof Richard Thaler of fights with traditional thinkers of economics to study such anomalies and the way these studies went into making policies for USA, UK and eventually to many other countries.</p>

<p><img src="/assets/images/misbehaving_book.jpg" alt="Misbehaving: Making of behavioral economics" /></p>

<p>This is a complementary read to the most popular book by Kanheman who created the prospect theory “Thinking Fast and Slow”. For those who do not know about the book, it talks about common biases people have in the day to day life (and also how new-age marketing take advantage of it)</p>

<p><img src="/assets/images/thinking_fast_slow_book.jpg" alt="Thinking fast and slow" /></p>

<p>Some of the quotes from the book I enjoyed being</p>
<ul>
  <li>The house money effect-along with a tendency to extrapolate recent returns into the future-facilitates financial bubbles</li>
  <li>A huge company had spent hundreds of millions of dollars in promotion and never bother to figure out how and why it worked</li>
  <li>The purely economic man is indeed close to being a social moron. Economic theory has been much preoccupied with this rational fool</li>
  <li>The problem is that the inside view is so natural and accessible that it can influence the judgments even of people who understand the concepts</li>
  <li>Of course coaches are Humans. They tend to do things the way they have been always done because those decisions will not be second-guessed b the boss. Following the conventional wisdom keeps you from getting fired</li>
  <li>People get promoted until they reach the level of incompetence</li>
  <li>Employees treat default options as suggestions</li>
  <li>A regulation is asymmetrically paternalistic if it creates large benefits for those who make errors</li>
  <li>A nudge is some small feature in the environment that attracts our attention and influences our behavior</li>
  <li>Prompted choice, a term both more accurate and less politically challenged. When dealing with Humans, words matter.</li>
  <li>We can’t do evidence-based policy without evidence</li>
  <li>Risk of you’re afraid to leave your job and be an entrepreneur because that is where your health insurance is. You need to soften your damage risk</li>
</ul>

<h2 id="critical-thoughts">Critical thoughts</h2>
<p>While I agree with most of those experimental setups and results, the example of 23 projects and 3 managers</p>

<p>“After the investment is made, there is a 50% chance it will make a profit of $2 million, and a 50% chance it will lose $1 million. (Notice that the expected payoff of this investment is $500,000, since half the time they gain $2 million—an expected gain of $1 million—and half the time they lose a million—an expected loss of half a million. The company was large enough that a million-dollar loss, or even several of them, would not threaten its solvency.) I then asked by a show of hands who would take on this project. Of the twenty-three executives, only three said they would do it.”</p>

<p>Even if I am in a room where this thought experiment is carried out, I will not be in the 3 managers who would say yes. The reason being, I may not be good at concluding the risks of a 1 million $ project especially in front of a CEO and an external person unless I am right to the smallest detail. Secondly, a project of 1 million$ would be a team effort and would be part of a “diversified portfolio” of things the team would do. That means if I am a manager allowed to handle that, the only thing company has to make sure is that 1 million dollars is not the only thing I bring to the table. Just make it as 30%-50% of what I bring to the table and I would take that risk easily (risk diversification and impact reduction)</p>

<p>Footnote: Does this make me a better person? Yes. Knowing what I do not know and knowing there are methods to detect and cope with those problems is the first step.</p>]]></content><author><name>Giree</name></author><category term="books" /><category term="inspiration" /><summary type="html"><![CDATA[Do you often]]></summary></entry><entry><title type="html">Malayalam Transliterator with next word prediction</title><link href="http://localhost:4000/malayalam-transliterator-with-next-word-prediction/" rel="alternate" type="text/html" title="Malayalam Transliterator with next word prediction" /><published>2020-11-01T00:00:00+00:00</published><updated>2020-11-01T00:00:00+00:00</updated><id>http://localhost:4000/malayalam-transliterator-with-next-word-prediction</id><content type="html" xml:base="http://localhost:4000/malayalam-transliterator-with-next-word-prediction/"><![CDATA[<p>മലയാളം എഴുത്ത് ഉപകരണ പരീക്ഷണം 
എല്ലാവർക്കും കേരള പിരവി ആശംസകൾ</p>

<p>This is an experiment on malayalam transliteration with next set of word prediction.  Just start typing in Manglish. From suggestions, select the word and press space.</p>
<iframe src="https://secure-shelf-14370.herokuapp.com/" title="Malayalam Transliterator" width="100%" height="1000" frameborder="0" allowtransparency="true"></iframe>

<h2 id="courtsy">Courtsy</h2>
<ul>
  <li>Transliteration API is from api.varnamproject.com (https://github.com/varnamproject)</li>
  <li>The front end was adapted from manghish repository (https://github.com/krishnanunnir/manglish)</li>
  <li>The word2vec data is obtained from AI4Bharat (https://indicnlp.ai4bharat.org/home/)</li>
  <li>The stemmer used in word2vec is from MLMorph (https://github.com/smc/mlmorph)</li>
</ul>]]></content><author><name>Giree</name></author><summary type="html"><![CDATA[മലയാളം എഴുത്ത് ഉപകരണ പരീക്ഷണം എല്ലാവർക്കും കേരള പിരവി ആശംസകൾ]]></summary></entry><entry><title type="html">Teapot: Simplifying statistical tests with a click</title><link href="http://localhost:4000/teapot-simplifying-statistical-tests-with-a-click/" rel="alternate" type="text/html" title="Teapot: Simplifying statistical tests with a click" /><published>2020-10-31T00:00:00+00:00</published><updated>2020-10-31T00:00:00+00:00</updated><id>http://localhost:4000/teapot-simplifying-statistical-tests-with-a-click</id><content type="html" xml:base="http://localhost:4000/teapot-simplifying-statistical-tests-with-a-click/"><![CDATA[<p>For beginners and non-programmers, getting statistical tests done could create headaches.  What if we only want to know if there is a relationship between one of the independent variable and the outcome (and leave the pre-conditions and finding suitable tests by a program) 
This is everything this post is about.</p>

<p>All that you need is to drag and drop your data in CSV Format (only the first 500 rows will be processed in this demo).  The application does</p>
<ul>
  <li>Data Cleanup</li>
  <li>Checks variable types (nominal/interval)</li>
  <li>Runs default relationship tests</li>
  <li>Serves the results in a table</li>
  <li>As a user, you can select one of the independent variables and the application runs one-sided/two-sided statistical tests (if applicable)</li>
</ul>

<h1 id="screenshots">Screenshots</h1>
<p><img src="/assets/images/wine_quality_file_load.jpg" alt="data load " /></p>

<p><img src="/assets/images/wine_quality_default_tests.jpg" alt="data load " /></p>

<p><img src="/assets/images/teapot_ar_condition_cleanup.jpg" alt="data load " /></p>

<p><img src="/assets/images/teapot_ar_condition.jpg" alt="data load " /></p>

<iframe src="https://shocking-cheateau-82195.herokuapp.com/" title="statistical tests" width="100%" height="1000" frameborder="0" allowtransparency="true"></iframe>

<h2 id="tealang-the-engine-underneath-the-application">Tealang: The engine underneath the application</h2>

<p>Underneath the application is <a href="https://github.com/tea-lang-org/tea-lang">tealang</a> (python library). To know about the library and why it was written, please watch the video below.</p>

<!-- Courtesy of embedresponsively.com //-->

<div class="responsive-video-container">
    <iframe src="https://www.youtube-nocookie.com/embed/eyoAqNKTjGQ" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
  </div>

<h2 id="source-code">Source code</h2>
<p><a href="https://github.com/sahyagiri/osm_roads">Tepot UI</a></p>]]></content><author><name>Giree</name></author><summary type="html"><![CDATA[For beginners and non-programmers, getting statistical tests done could create headaches. What if we only want to know if there is a relationship between one of the independent variable and the outcome (and leave the pre-conditions and finding suitable tests by a program) This is everything this post is about.]]></summary></entry><entry><title type="html">Bring your own data</title><link href="http://localhost:4000/bring-your-own-data/" rel="alternate" type="text/html" title="Bring your own data" /><published>2020-10-18T00:00:00+00:00</published><updated>2020-10-18T00:00:00+00:00</updated><id>http://localhost:4000/bring-your-own-data</id><content type="html" xml:base="http://localhost:4000/bring-your-own-data/"><![CDATA[<p>One of the reasons of I love Software Engineering is  because, with right user experience; even a layman can start using any software tool.  When it comes to data analysis, for subject experts (doctors, public health workers, bankers and many others), getting the head around R or Python or even automl is bit hard. This blog and the below tool is an experiment on bringing in data analysis without the theory.  This is a very simple automl framework which is running in a server so that you do not need to install any software to try it out.</p>

<p>Please add your comments at the bottom of the page on the use of such a tool/how this could be made better etc</p>
<h2 id="how-to-get-started">How to get started</h2>
<p>You would need a dataset with independant variables and the outcome variables.  Let us say, we are analysing Mushrooms are edible or poisonous. For thtat we collected properties of mushrooms. The concepts of the input table in CSV is shown below .</p>

<p><img src="/assets/images/csv_table_explanation_classification.jpg" alt="mushroom classification" /></p>

<p>You can proceed with the instructions after preparing such data on your field of interest. 
To try out sample datasets, please use <a href="https://datasetsearch.research.google.com/search?query=health&amp;docid=xvsrhW6jbJriqg%2BEAAAAAA%3D%3D&amp;filters=WyJbXCJmaWxlX2Zvcm1hdF9jbGFzc1wiLFtcIjZcIl1dIl0%3D&amp;property=ZmlsZV9mb3JtYXRfY2xhc3M%3D">google dataset search</a></p>

<h3 id="animation-explaining-the-steps">Animation explaining the steps</h3>
<p><img src="/assets/images/how_to_use_the_analysis_portal.gif" alt="Instructions" /></p>

<p>If you are confused on how to interpret the charts below, please have a <a href="https://dossiers.page/how-to-reduce-heart-disease-risk-an-exploratory-model-analysis-on-open-data-set/">look at the previous post</a></p>
<h3 id="please-wait-for-the-below-application-to-load">Please wait for the below application to load</h3>
<iframe src="https://pythonapps.dossiers.page:7443/" title="EMA" width="100%" height="4260" frameborder="0" allowtransparency="true"></iframe>

<h2 id="what-is-happening-behind-the-scenes">What is happening behind the scenes</h2>
<ol>
  <li>The application downlods 500 rows of the data</li>
  <li>Analyses the outcome/target variable and determines the analysis type (Classification/Regression)</li>
  <li>Remove constant/highly correlated/identifier/ high in null values</li>
  <li>Encodes categorical variables</li>
  <li>Create an ensemble model (RandomForest) using the data</li>
  <li>The relationships found by model is output using SHAP values (Top 10 features)</li>
  <li>Statistical tests between all the control variables and the outcome  (displays up to top 10 values sorted with lowest P-Values)</li>
  <li>Plots Partial Dependance Plot of top 3 continuous variables</li>
</ol>

<h2 id="limitations-and-caveats">Limitations and Caveats</h2>
<ul>
  <li>The analysis only covers two types (classification and regression)</li>
  <li>The analysis is done only on first 500 rows as it runs on a free server</li>
  <li>If the analysis is classification, the shap plot importance is showing the outcome for one of the outcomes (say [male,female] –&gt; Plots might be for Female)</li>
  <li>The model is trained only with minimal number of trees (50)</li>
  <li>Statistical outcomes are based on automated analysis by Tea-Lang (please see the video here for more details)</li>
</ul>

<h2 id="what-happens-to-the-data-does-this-web-site-or-associated-sites-store-the-data">What happens to the data/ does this web site or associated sites store the data?</h2>
<p>For academic interests, this web sites captures the column headers of the data.  But the data itself or the analysis results are not stored</p>
<h2 id="what-if-you-are-interested-in-more-detailed-analysis-of-your-data">What if you are interested in more detailed analysis of your data</h2>
<p>Please drop a mail to giri@dossiers.page with your initial report from the page</p>
<h2 id="acknoledgements">Acknoledgements</h2>
<ol>
  <li>The application’s auto-detection of statistical tests is made possible by (https://tea-lang.org/). Please watch the introduction video by the author of Tea-Lang here (https://www.youtube.com/watch?v=eyoAqNKTjGQ&amp;t=1705s)</li>
  <li>The Application UI is built using Streamlit (https://www.streamlit.io/)</li>
  <li>The shap value plots are using shap library (https://github.com/slundberg/shap/)</li>
  <li>The Plots are done using PDPBox  (https://github.com/SauceCat/PDPbox)</li>
</ol>]]></content><author><name>Giree</name></author><summary type="html"><![CDATA[One of the reasons of I love Software Engineering is because, with right user experience; even a layman can start using any software tool. When it comes to data analysis, for subject experts (doctors, public health workers, bankers and many others), getting the head around R or Python or even automl is bit hard. This blog and the below tool is an experiment on bringing in data analysis without the theory. This is a very simple automl framework which is running in a server so that you do not need to install any software to try it out.]]></summary></entry><entry><title type="html">Heart Disease Demo: How much risk for a single patient has</title><link href="http://localhost:4000/heart-disease-demo/" rel="alternate" type="text/html" title="Heart Disease Demo: How much risk for a single patient has" /><published>2020-10-05T00:00:00+00:00</published><updated>2020-10-05T00:00:00+00:00</updated><id>http://localhost:4000/heart-disease-demo</id><content type="html" xml:base="http://localhost:4000/heart-disease-demo/"><![CDATA[<p>The previous post explained, overall, what factors affect health of the heart. This is the global interpretability of machine learning. A better tool for a subject matter expert to try out is on the boundary conditions. Here, he/she can put values which even confuses the experts; and see how well the model behaves. This is called <strong>local interpretability</strong>.  This post is an example of local interpretability and how the model behaves well and erratically, given the input conditions.</p>

<p>The method used here is the use of <a href="https://en.wikipedia.org/wiki/Shapley_value">SHAPELY  values</a>. To get an idea how this works, think of a game where each team member contributes to the final score.</p>
<h2 id="a-note-on-the-parameters-used-in-the-demo">A note on the parameters used in the demo</h2>
<ul>
  <li>Age: Age completed in years</li>
  <li>Resting blood pressure : Level of blood pressure at resting mode in mm/HG (Systoloc)</li>
  <li>Cholesterol: Serum cholesterol in mg/dl</li>
  <li>Maximum Heart Rate Achieved: Heart rate achieved while doing a treadmill test or exercise</li>
  <li>ST_Depression/oldpeak: Exercise induced ST-depression in comparison with the state of rest</li>
  <li>Sex: Gender of patient (The data had only male and female)</li>
  <li>Chest Pain Type: Type of chest pain experienced by patient</li>
  <li>Fasting blood sugar: Blood sugar levels on fasting &gt; 120 mg/dl represents as 1 in case of true and 0 as false</li>
  <li>Resting ecg: Result of electrocardiogram while at rest</li>
  <li>Exercise angina: Angina induced by exercise 0 depicting NO 1 depicting Yes</li>
  <li>ST slope: ST segment measured in terms of slope during peak exercise
    <h2 id="try-it-out">Try it out</h2>
    <p>(If you are loading this for first time, click on show widgets below, to load the application. Best viewed in bigger screen)</p>
  </li>
</ul>
<div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container">
			
  <div class="cell text_cell">
    <button class="js-nbinteract-widget">
      Loading widgets...
    </button>
  </div>




  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#HIDDEN</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">shap</span>
<span class="kn">import</span> <span class="nn">joblib</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">mpatches</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">TransformerMixin</span><span class="p">,</span> <span class="n">BaseEstimator</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">Categorical</span><span class="p">,</span> <span class="n">get_dummies</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interact_manual</span><span class="p">,</span><span class="n">interactive</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">Layout</span><span class="p">,</span> <span class="n">Button</span><span class="p">,</span> <span class="n">Box</span><span class="p">,</span> <span class="n">VBox</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">Button</span><span class="p">,</span> <span class="n">HBox</span><span class="p">,</span> <span class="n">VBox</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">Layout</span><span class="p">,</span> <span class="n">Button</span><span class="p">,</span> <span class="n">Box</span><span class="p">,</span> <span class="n">FloatText</span><span class="p">,</span> <span class="n">Textarea</span><span class="p">,</span> <span class="n">Dropdown</span><span class="p">,</span> <span class="n">Label</span><span class="p">,</span> <span class="n">IntSlider</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="c1">#HIDDEN</span>
<span class="k">class</span> <span class="nc">CategoricalPreprocessing</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__get_categorical_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data_frame</span><span class="p">,</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.70</span><span class="p">,</span> <span class="n">top_n_values</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">likely_categorical</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">data_frame</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="k">if</span> <span class="mf">1.</span> <span class="o">*</span> <span class="n">data_frame</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">top_n_values</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span>
                <span class="n">likely_categorical</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">likely_categorical</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;st_depression&#39;</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span> 
        <span class="k">return</span> <span class="n">likely_categorical</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_categorical_variables</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">cats</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span><span class="p">:</span>
            <span class="n">cats</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">categoricals</span> <span class="o">=</span> <span class="n">cats</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attribute_names</span><span class="p">:</span>
            <span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">],</span> <span class="n">categories</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">categoricals</span><span class="p">[</span><span class="n">column</span><span class="p">])</span>
        <span class="n">new_df</span> <span class="o">=</span> <span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># in case we need them later</span>
        <span class="k">return</span> <span class="n">new_df</span>
<span class="c1">#HIDDEN</span>
<span class="n">feature_model</span><span class="o">=</span><span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;random_forest_heart_model_v2&#39;</span><span class="p">)</span>
<span class="n">categorical_transform</span><span class="o">=</span><span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;categorical_transform_v2&#39;</span><span class="p">)</span>
<span class="n">explainer_random_forest</span><span class="o">=</span><span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;shap_random_forest_explainer_v2&#39;</span><span class="p">)</span>
<span class="n">numerical_options</span><span class="o">=</span><span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;numerical_options_dictionary_v2&#39;</span><span class="p">)</span>
<span class="n">categorical_options</span><span class="o">=</span><span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;categorical_options_dictionary_v2&#39;</span><span class="p">)</span>


<span class="n">ui_elements</span><span class="o">=</span><span class="p">[]</span>
<span class="n">style</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;description_width&#39;</span><span class="p">:</span> <span class="s1">&#39;initial&#39;</span><span class="p">}</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">numerical_options</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">minimum</span><span class="o">=</span><span class="n">numerical_options</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;minimum&#39;</span><span class="p">]</span>
    <span class="n">maximum</span><span class="o">=</span><span class="n">numerical_options</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;maximum&#39;</span><span class="p">]</span>
    <span class="n">default</span><span class="o">=</span><span class="n">numerical_options</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;default&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">!=</span><span class="s1">&#39;st_depression&#39;</span><span class="p">:</span>
        <span class="n">ui_elements</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="n">default</span><span class="p">,</span>
        <span class="nb">min</span><span class="o">=</span><span class="n">minimum</span><span class="p">,</span>
        <span class="nb">max</span><span class="o">=</span><span class="n">maximum</span><span class="p">,</span>
        <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="n">i</span><span class="p">,</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">)</span>
                      <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ui_elements</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="n">default</span><span class="p">,</span>
        <span class="nb">min</span><span class="o">=</span><span class="n">minimum</span><span class="p">,</span>
        <span class="nb">max</span><span class="o">=</span><span class="n">maximum</span><span class="p">,</span>
        <span class="n">step</span><span class="o">=.</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="n">i</span><span class="p">,</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">)</span>
                      <span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">categorical_options</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">ui_elements</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">Dropdown</span><span class="p">(</span>
    <span class="n">options</span><span class="o">=</span><span class="n">categorical_options</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;options&#39;</span><span class="p">],</span>
    <span class="n">value</span><span class="o">=</span><span class="n">categorical_options</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;default&#39;</span><span class="p">],</span>
    <span class="n">description</span><span class="o">=</span><span class="n">i</span><span class="p">,</span><span class="n">style</span><span class="o">=</span><span class="n">style</span>
    <span class="p">))</span>
<span class="n">interact_calc</span><span class="o">=</span><span class="n">interact</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">manual</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">manual_name</span><span class="o">=</span><span class="s2">&quot;Calculate Risk&quot;</span><span class="p">)</span>

<span class="c1">#HIDDEN</span>
<span class="k">def</span> <span class="nf">get_risk_string</span><span class="p">(</span><span class="n">prediction_probability</span><span class="p">):</span>
    <span class="n">y_val</span> <span class="o">=</span> <span class="n">prediction_probability</span><span class="o">*</span> <span class="mi">100</span>
    <span class="n">text_val</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="s2">&quot;% | &quot;</span>

    <span class="c1"># assign a risk group</span>
    <span class="k">if</span> <span class="n">y_val</span> <span class="o">/</span> <span class="mi">100</span> <span class="o">&lt;=</span> <span class="mf">0.275685</span><span class="p">:</span>
        <span class="n">risk_grp</span> <span class="o">=</span> <span class="s1">&#39; low risk &#39;</span>
    <span class="k">elif</span> <span class="n">y_val</span> <span class="o">/</span> <span class="mi">100</span> <span class="o">&lt;=</span> <span class="mf">0.795583</span><span class="p">:</span>
        <span class="n">risk_grp</span> <span class="o">=</span> <span class="s1">&#39; medium risk &#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">risk_grp</span> <span class="o">=</span> <span class="s1">&#39; high risk &#39;</span>
    
    <span class="k">return</span> <span class="n">text_val</span><span class="o">+</span> <span class="n">risk_grp</span>
<span class="k">def</span> <span class="nf">get_current_prediction</span><span class="p">():</span>
    <span class="n">current_values</span><span class="o">=</span><span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">ui_elements</span><span class="p">:</span>
        <span class="n">current_values</span><span class="p">[</span><span class="n">element</span><span class="o">.</span><span class="n">description</span><span class="p">]</span><span class="o">=</span><span class="n">element</span><span class="o">.</span><span class="n">value</span>
    <span class="n">feature_row</span><span class="o">=</span><span class="n">categorical_transform</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">([</span><span class="n">current_values</span><span class="p">]))</span>
    <span class="n">feature_row</span><span class="o">=</span><span class="n">feature_row</span><span class="p">[[</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;resting_blood_pressure&#39;</span><span class="p">,</span> <span class="s1">&#39;cholesterol&#39;</span><span class="p">,</span>
       <span class="s1">&#39;max_heart_rate_achieved&#39;</span><span class="p">,</span> <span class="s1">&#39;st_depression&#39;</span><span class="p">,</span> <span class="s1">&#39;sex_female&#39;</span><span class="p">,</span> <span class="s1">&#39;sex_male&#39;</span><span class="p">,</span>
       <span class="s1">&#39;chest_pain_type_non-anginal pain&#39;</span><span class="p">,</span> <span class="s1">&#39;chest_pain_type_asymptomatic&#39;</span><span class="p">,</span>
       <span class="s1">&#39;chest_pain_type_atypical angina&#39;</span><span class="p">,</span> <span class="s1">&#39;chest_pain_type_typical angina&#39;</span><span class="p">,</span>
       <span class="s1">&#39;fasting_blood_sugar_0&#39;</span><span class="p">,</span> <span class="s1">&#39;fasting_blood_sugar_1&#39;</span><span class="p">,</span> <span class="s1">&#39;rest_ecg_normal&#39;</span><span class="p">,</span>
       <span class="s1">&#39;rest_ecg_ST-T wave abnormality&#39;</span><span class="p">,</span>
       <span class="s1">&#39;rest_ecg_left ventricular hypertrophy&#39;</span><span class="p">,</span> <span class="s1">&#39;exercise_induced_angina_0&#39;</span><span class="p">,</span>
       <span class="s1">&#39;exercise_induced_angina_1&#39;</span><span class="p">,</span> <span class="s1">&#39;st_slope_flat&#39;</span><span class="p">,</span> <span class="s1">&#39;st_slope_upsloping&#39;</span><span class="p">,</span>
       <span class="s1">&#39;st_slope_downsloping&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    
   
    
    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer_random_forest</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">feature_row</span><span class="p">)</span>
    
   
    
    
    <span class="n">updated_fnames</span> <span class="o">=</span> <span class="n">feature_row</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
    <span class="n">updated_fnames</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">,</span> <span class="s1">&#39;value&#39;</span><span class="p">]</span>
    
    
    <span class="n">risk_prefix</span><span class="o">=</span><span class="s1">&#39;&lt;h2&gt; Risk Level :&#39;</span>
    <span class="n">risk_suffix</span><span class="o">=</span><span class="s1">&#39;&lt;/h2&gt;&#39;</span>
    <span class="n">risk_probability</span><span class="o">=</span><span class="n">feature_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">feature_row</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">risk_string</span><span class="o">=</span><span class="n">get_risk_string</span><span class="p">(</span><span class="n">risk_probability</span><span class="p">)</span>
    <span class="n">risk_widget</span><span class="o">.</span><span class="n">value</span><span class="o">=</span><span class="n">risk_prefix</span><span class="o">+</span><span class="n">risk_string</span><span class="o">+</span><span class="n">risk_suffix</span>
    <span class="n">updated_fnames</span><span class="p">[</span><span class="s1">&#39;shap_original&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">shap_values</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">updated_fnames</span><span class="p">[</span><span class="s1">&#39;shap_abs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">updated_fnames</span><span class="p">[</span><span class="s1">&#39;shap_original&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>

    <span class="n">updated_fnames</span><span class="o">=</span><span class="n">updated_fnames</span><span class="p">[</span><span class="n">updated_fnames</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span><span class="o">!=</span><span class="mi">0</span><span class="p">]</span>
    
    
    
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">})</span>
    <span class="n">df1</span><span class="o">=</span><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">updated_fnames</span><span class="p">[</span><span class="s2">&quot;shap_original&quot;</span><span class="p">])</span>
    <span class="n">df1</span><span class="o">.</span><span class="n">index</span><span class="o">=</span><span class="n">updated_fnames</span><span class="o">.</span><span class="n">feature</span>
    <span class="n">df1</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;shap_original&#39;</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">df1</span><span class="p">[</span><span class="s1">&#39;positive&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df1</span><span class="p">[</span><span class="s1">&#39;shap_original&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">df1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;barh&#39;</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">7</span><span class="p">,),</span><span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1">#HIDDEN</span>
<span class="n">form_item_layout</span> <span class="o">=</span> <span class="n">Layout</span><span class="p">(</span>
    <span class="n">display</span><span class="o">=</span><span class="s1">&#39;flex&#39;</span><span class="p">,</span>
    <span class="n">flex_flow</span><span class="o">=</span><span class="s1">&#39;row&#39;</span><span class="p">,</span>
    <span class="n">justify_content</span><span class="o">=</span><span class="s1">&#39;space-between&#39;</span>
<span class="p">)</span>

<span class="n">form_items</span> <span class="o">=</span> <span class="n">ui_elements</span>

<span class="n">form</span> <span class="o">=</span> <span class="n">Box</span><span class="p">(</span><span class="n">form_items</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span>
    <span class="n">display</span><span class="o">=</span><span class="s1">&#39;flex&#39;</span><span class="p">,</span>
    <span class="n">flex_flow</span><span class="o">=</span><span class="s1">&#39;column&#39;</span><span class="p">,</span>
   
    <span class="n">align_items</span><span class="o">=</span><span class="s1">&#39;stretch&#39;</span>
   
<span class="p">))</span>


<span class="n">box_layout</span> <span class="o">=</span> <span class="n">Layout</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="s1">&#39;flex&#39;</span><span class="p">,</span>
                    <span class="n">flex_flow</span><span class="o">=</span><span class="s1">&#39;column&#39;</span>
                    <span class="p">)</span>

<span class="n">left_box</span> <span class="o">=</span> <span class="n">VBox</span><span class="p">(</span><span class="n">ui_elements</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
<span class="n">right_box</span> <span class="o">=</span> <span class="n">VBox</span><span class="p">(</span><span class="n">ui_elements</span><span class="p">[</span><span class="mi">5</span><span class="p">:])</span>
<span class="n">control_layout</span><span class="o">=</span><span class="n">VBox</span><span class="p">([</span><span class="n">left_box</span><span class="p">,</span><span class="n">right_box</span><span class="p">],</span><span class="n">layout</span><span class="o">=</span><span class="n">box_layout</span><span class="p">)</span>

<span class="n">risk_string</span><span class="o">=</span><span class="s2">&quot;&lt;h2&gt;Risk Level&lt;/h2&gt;&quot;</span>

<span class="n">risk_widget</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">risk_string</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

  </div>

  

  <div class="nbinteract-hide_in
      cell border-box-sizing code_cell rendered">
    <div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#HIDDEN</span>
<span class="n">display</span><span class="p">(</span><span class="n">control_layout</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">Box</span><span class="p">(</span><span class="n">children</span><span class="o">=</span><span class="p">[</span><span class="n">risk_widget</span><span class="p">]))</span>
<span class="n">risk_plot</span><span class="o">=</span><span class="n">interact_calc</span><span class="p">(</span><span class="n">get_current_prediction</span><span class="p">)</span>

<span class="n">risk_plot</span><span class="o">.</span><span class="n">widget</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">button_color</span> <span class="o">=</span> <span class="s1">&#39;lightblue&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    



  <div class="output_subarea output_widget_view ">
    <button class="js-nbinteract-widget">
      Loading widgets...
    </button>
  </div>

</div>

<div class="output_area">

    



  <div class="output_subarea output_widget_view ">
    <button class="js-nbinteract-widget">
      Loading widgets...
    </button>
  </div>

</div>

<div class="output_area">

    



  <div class="output_subarea output_widget_view ">
    <button class="js-nbinteract-widget">
      Loading widgets...
    </button>
  </div>

</div>

</div>
</div>

  </div>



<!-- Loads nbinteract package -->
<script src="https://unpkg.com/nbinteract-core" async=""></script>
<script>
  (function setupNbinteract() {
    // If NbInteract hasn't loaded, wait one second and try again
    if (window.NbInteract === undefined) {
      setTimeout(setupNbinteract, 1000)
      return
    }

    var interact = new window.NbInteract({
      spec: 'sahyagiri/heart_risk_local/master',
      baseUrl: 'https://mybinder.org',
      provider: 'gh',
    })
    interact.prepare()

    window.interact = interact
  })()
</script>
    </div>
  </div>

<p>Please note: This is running in free servers and you may need to wait for it to load correctly.</p>

<h2 id="below-image-shows-how-the-interaction-below-is-supposed-to-render">Below image shows how the interaction (below) is supposed to render</h2>

<p><img src="/assets/images/local_explanation_example_1.jpg" alt="Local interpretation of heart disease" /></p>

<p>The things on positive axis contribute positively to the heart risk and things on negative axis contribute towards good heart health.</p>

<h2 id="below-image-shows-if-we-reduce-the-risk">Below image shows if we reduce the risk</h2>

<p><img src="/assets/images/local_explanation_example_2_healthy.jpg" alt="Local interpretation of heart disease" /></p>

<p>Here we can see if a person is healthy at 57 years, how the lab results and the corresponding risk would look like</p>

<h2 id="an-anomaly-with-cholesterol-levels">An anomaly with cholesterol levels</h2>

<p><img src="/assets/images/local_explanation_example_3_anomaly.jpg" alt="Local interpretation of heart disease" /></p>

<p>** Here the model thinks that high cholesterol is good for health.    **</p>

<p>This is why it is always important to give interactive widgets to the subject matter experts (here a doctor) to try it out first than giving a set of charts. 
The next iteration in a model building would be to look at the data and see what pattern emerges which makes this/ train a different model/ tune the model parameter to look for specific patterns.</p>

<h3 id="disclaimer">Disclaimer:</h3>
<p>This is a demonstration of how machine learning models can be trained on available patient data and the study of how the model works in new data. Please do consult a doctor for actual interpretations and risk factors.</p>

<p><strong>Acknowledgements</strong></p>

<p>The dataset is taken from three other research datasets used in different research papers. The Nature article listing heart disease database and names of popular datasets used in various heart disease research is shared below.
https://www.nature.com/articles/s41597-019-0206-3</p>

<p>The data set is consolidated and <a href="https://www.kaggle.com/sid321axn/heart-statlog-cleveland-hungary-final">made available in kaggle</a></p>

<p>Thanks to <a href="https://www.kaggle.com/sid321axn/stacked-ensemble-for-heart-disease-classification">this wonderful post in Kaggle</a> which I have used in data clean up</p>]]></content><author><name>Giree</name></author><category term="EMA" /><category term="exploratory_model_analysis" /><category term="xai" /><category term="explainable_ai" /><summary type="html"><![CDATA[The previous post explained, overall, what factors affect health of the heart. This is the global interpretability of machine learning. A better tool for a subject matter expert to try out is on the boundary conditions. Here, he/she can put values which even confuses the experts; and see how well the model behaves. This is called local interpretability. This post is an example of local interpretability and how the model behaves well and erratically, given the input conditions.]]></summary></entry><entry><title type="html">Are we progressing as human?</title><link href="http://localhost:4000/are-we-progressing-as-human/" rel="alternate" type="text/html" title="Are we progressing as human?" /><published>2020-09-20T00:00:00+00:00</published><updated>2020-09-20T00:00:00+00:00</updated><id>http://localhost:4000/are-we-progressing-as-human</id><content type="html" xml:base="http://localhost:4000/are-we-progressing-as-human/"><![CDATA[<p>When I see the news like China and India has the highest population and in a race of population growth; I wonder how easy it is to have resources for all. Is this a correct understanding of the world?
<img src="/assets/images/gapminder_babies_per_women.jpg" alt="Number of children per woman " />
    <em>picture courtsy:  gapminder.org</em></p>

<p>If we look at the data, we might be surprised to see that the number of children per woman is falling.  That is counter-intuitive to common beliefs. To understand the reasons of such trend, one must understand the data analysis around the world, especially that on infant mortality. That means, families, when they realise that their child has a higher survival chance and access to birth control can stabilize the population. This is a miracle of public health systems, including vaccination policies, eradication programs like Polio, clean drinking water facilities and improved sanitization. 
<img src="/assets/images/polio_india_campaign.jpg" alt="polio eradication in India, campaign" />.</p>

<p><img src="/assets/images/swach_bharat.JPG" alt="Swach Bharat Abhiyan " />.</p>

<p>If you are curious on how the world changed, and continues to change towards a better society, the place you need to look at is <a href="https://gapminder.org/">GapMinder</a> or read the book by Hans Rosling (<img src="https://upload.wikimedia.org/wikipedia/en/b/b2/Factfulness_Ten_Reasons_We%27re_Wrong_About_the_World--and_Why_Things_Are_Better_Than_You_Think.jpg" alt="Factfulness" /><br />
<em>photo from wikimedia commons</em></p>

<!-- Courtesy of embedresponsively.com //-->

<div class="responsive-video-container">
    <iframe src="https://www.youtube-nocookie.com/embed/hVimVzgtD6w" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
  </div>

<p>If you are too lazy and need inspiration to read this book, please look at the above TED Talk by Rosling</p>
<h2 id="the-poverty-trap-and-effect-of-economic-policies">The poverty trap and effect of economic policies</h2>
<p>The next in line on the human progression is the poverty. Typical things poor people do is to do multiple jobs, start small business and see if they can save and move out. is this effective?   The challenges here are in the initial investment (Capital Investment) and sustaining the business during uncertainities or changes in situation.  Poor normally lends from loan sharks and not from banks. These behaviors from poor are extremely short sighted,  makes them stay poor like the victorian thought <em>this was how poor were</em>.  The long term view seems to come only when there is job stabilty and constant revenue soure.</p>

<p>How to understand those changes and causality analysis, why poor stay poor and what changes the state are described in the <a href="https://www.amazon.in/Poor-Economics-Rethinking-Poverty-Ways/dp/8184002807">book</a> by Abhijit Banerjee</p>

<p><img src="/assets/images/poor_economics.jpg" alt="poor economics book" />.</p>

<p>If you want to look further into the effect of leadership change or policy change and what statistical methods used in accessing these can be found at the course <a href="https://courses.edx.org/courses/course-v1:MITx+14.750x+3T2020/course/">Political Economy </a></p>

<p><img src="/assets/images/political_economy_course.jpg" alt="EDX Course on Political Economics" />.</p>]]></content><author><name>Giree</name></author><category term="books" /><summary type="html"><![CDATA[When I see the news like China and India has the highest population and in a race of population growth; I wonder how easy it is to have resources for all. Is this a correct understanding of the world? picture courtsy: gapminder.org]]></summary></entry></feed>